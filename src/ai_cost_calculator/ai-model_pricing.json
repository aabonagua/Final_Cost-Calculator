{
  "_meta": {
    "schema_version": "1.0",
    "last_updated": "2026-01-14",
    "currency": "USD",
    "sources": {
      "openai": {
        "name": "OpenAI Pricing",
        "url": "https://platform.openai.com/pricing"
      },
      "google": {
        "name": "Google Gemini Pricing",
        "url": "https://ai.google.dev/pricing"
      }
    },
    "notes": "All prices are normalized to USD. Token-based prices are per 1M tokens unless otherwise stated. Cached input applies only when supported by the model. Gemini tiered pricing depends on prompt size thresholds."
  },

  
  "openai": {
    "billing_unit_tokens": 1000000,
    "models": {
      "gpt-5.2": {
        "input": 1.75,
        "cached_input": 0.175,
        "output": 14.0,
        "aliases": ["gpt-5.2-chat-latest"]
      },
      "gpt-5.1": {
        "input": 1.25,
        "cached_input": 0.125,
        "output": 10.0,
        "aliases": [
          "gpt-5",
          "gpt-5-chat-latest",
          "gpt-5.1-chat-latest",
          "gpt-5-codex",
          "gpt-5.1-codex",
          "gpt-5.1-codex-max"
        ]
      },
      "gpt-5.2-pro": {
        "input": 21.0,
        "cached_input": null,
        "output": 168.0,
        "aliases": []
      },
      "gpt-5-pro": {
        "input": 15.0,
        "cached_input": null,
        "output": 120.0,
        "aliases": []
      },
      "gpt-5-mini": {
        "input": 0.25,
        "cached_input": 0.025,
        "output": 2.0,
        "aliases": []
      },
      "gpt-5-nano": {
        "input": 0.05,
        "cached_input": 0.005,
        "output": 0.40,
        "aliases": []
      },
      "gpt-4.1": {
        "input": 2.0,
        "cached_input": 0.50,
        "output": 8.0,
        "aliases": []
      },
      "gpt-4.1-mini": {
        "input": 0.40,
        "cached_input": 0.10,
        "output": 1.60,
        "aliases": []
      },
      "gpt-4.1-nano": {
        "input": 0.10,
        "cached_input": 0.025,
        "output": 0.40,
        "aliases": []
      },
      "gpt-4o": {
        "input": 2.50,
        "cached_input": 1.25,
        "output": 10.0,
        "aliases": ["gpt-4o-2024-05-13"]
      },
      "gpt-4o-mini": {
        "input": 0.15,
        "cached_input": 0.075,
        "output": 0.60,
        "aliases": []
      },
      "gpt-realtime": {
        "input": 4.0,
        "cached_input": 0.40,
        "output": 16.0,
        "aliases": []
      },
      "gpt-realtime-mini": {
        "input": 0.60,
        "cached_input": 0.06,
        "output": 2.40,
        "aliases": []
      },
      "gpt-4o-realtime-preview": {
        "input": 5.0,
        "cached_input": 2.50,
        "output": 20.0,
        "aliases": []
      },
      "gpt-4o-mini-realtime-preview": {
        "input": 0.60,
        "cached_input": 0.30,
        "output": 2.40,
        "aliases": []
      }
    }
  },

  "google": {
    "billing_unit_tokens": 1000000,
    "models": {
      "gemini-2.5-pro": {
        "tiers": [
          {
            "max_input_tokens": 200000,
            "input": 1.25,
            "output": 10.0,
            "context_cache": 0.125,
            "storage_per_hour": 4.5
          },
          {
            "max_input_tokens": null,
            "input": 2.5,
            "output": 15.0,
            "context_cache": 0.25,
            "storage_per_hour": 4.5
          }
        ]
      },

      "gemini-2.5-flash": {
        "tiers": [
          {
            "max_input_tokens": null,
            "input": 0.30,
            "output": 2.5,
            "context_cache": 0.03,
            "storage_per_hour": 1.0
          }
        ]
      },

      "gemini-2.5-flash-lite": {
        "tiers": [
          {
            "max_input_tokens": null,
            "input": 0.10,
            "output": 0.40,
            "context_cache": 0.01,
            "storage_per_hour": 1.0
          }
        ]
      },

      "gemini-2.5-flash-image": {
        "tiers": [
            {
              "max_input_tokens": null,
              "input": 0.30,
              "output": 0.039,
              "context_cache": null,
              "storage_per_hour": null
            }
          ]
      },

      "gemini-3-flash-preview": {
        "tiers": [
          {
            "max_input_tokens": null,
            "input": 0.50,
            "output": 3.0,
            "context_cache": 0.05,
            "storage_per_hour": 1.0
          }
        ]
      },

      "gemini-3-pro-preview": {
        "tiers": [
          {
            "max_input_tokens": 200000,
            "input": 2.0,
            "output": 12.0,
            "context_cache": 0.20,
            "storage_per_hour": 4.5
          },
          {
            "max_input_tokens": null,
            "input": 4.0,
            "output": 18.0,
            "context_cache": 0.40,
            "storage_per_hour": 4.5
          }
        ]
      }
    }
  }
}


